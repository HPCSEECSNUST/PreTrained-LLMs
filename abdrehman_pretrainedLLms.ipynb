{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74aioO0jOxSu",
        "outputId": "47a34a16-a814-4a8a-a70c-ccc392e0a91d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
      ],
      "metadata": {
        "id": "6wA_nWlNO53h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "rwWD4vquO50K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt,length=200):\n",
        "  inputs=tokenizer.encode(prompt, return_tensors=\"pt\",max_length=length)\n",
        "  outputs=model.generate(inputs, max_length=length, num_return_sequences=1, do_sample=True)\n",
        "  text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UUKYqp2DO5uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Once upon a time\",\n",
        "    \"Babar Azam is King\",\n",
        "    \"Imran Khan is great leader\"\n",
        "]"
      ],
      "metadata": {
        "id": "JPX4WdNyO5qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "  text = generate_text(prompt=prompt)\n",
        "  print(f\"{prompt}\\n{text}\")\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inoyq0gpO5nt",
        "outputId": "5a48f679-6bfb-4e25-e51b-62d22c0dff1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time\n",
            "Once upon a time before the Fall of Roman rule, a city could be destroyed and the city became a center for all things political and cultural. I would recommend you give those ideas a try right now and help others in need.\"\n",
            "\n",
            "I have two sons.\n",
            "\n",
            "My brother is an accountant, but works in finance and business. He's now in his late twenties and has been thinking about becoming a banker for the last 2 years.\n",
            "\n",
            "\"I'm trying to do something with my\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Babar Azam is King\n",
            "Babar Azam is King of India in his turn to rule Syria. He has always been suspicious of Iran during his brief tenure as president. In 2014 though, Iran publicly accused his government of supporting Bashar Assad.\n",
            "\n",
            "With this in mind, Abadi has tried to appease him with a string of foreign policy initiatives. After the collapse of the failed state of Egypt, he has vowed to use his power to establish more effective ties with international partners as well as develop trade, development, and\n",
            "\n",
            "\n",
            "\n",
            "Imran Khan is great leader\n",
            "Imran Khan is great leader, good coach, good mentor, good man and good man's friend, all things taken care of and he is at the best of circumstances, and I am with him.\"\n",
            "\n",
            "It's a statement so unexpected that the NFL wants to bring it up, and so different from what they had in mind when they first made the statement that Manziel was an out, untouchable receiver who was never going to be a superstar.\n",
            "\n",
            "So if we're going to\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLvMZv7oO5lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdGUmH8eO5i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wzyD5FP3O5gg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}